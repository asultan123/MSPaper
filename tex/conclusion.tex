\chapter{Conclusion}
\label{chap:conclude}

In this thesis, a Hybrid GEMM and Direct Convolution Accelerator (HERO) was
introduced as a neural network accelerator that preserves computation generality
by supporting matrix multiplication while maintaining computational efficiency
when running the common configurations of the convolution operation. The design
of HERO was derived from a data-aware design process, where a ConvolutIon
statIstics GAtherer (CIGAR) tool was used to identify the common case of the
convolution operation that needed to be supported by HERO directly. To optimize
HERO's configurations, a HERO Accelerator TEMPlate Optimizer (TEMPO) was
introduced. TEMPO was driven by an analytical model that maximizes on-chip PE
utilization. Furthermore, a novel descriptor-driven on-chip memory primitive
called Self-Addressable Memory (SAM) was presented, which enables
energy-efficient on-chip data movements within HERO. To convert arbitrary
Pytorch models to SAM descriptors, a HERO layer compiler was discussed. To
evaluate the performance and energy efficiency of various HERO configurations, a
cycle-accurate simulation platform driven by a SystemC simulation backend and a
Python evaluation frontend was developed. Finally, an analysis of an optimal
HERO configuration when running 695 networks in the TIMM library was presented.

HERO was found to perform well on a wide variety of network configurations. It
achieved a median FPS of ~91 FPS with a median speedup of 4.87X over CPU
baseline. The estimated bandwidth required for the configuration of HERO studied
was 19.65GiB which is within the PC4-21300 DDR4 specification. With that
configuration of DRAM the median inferences/J is 57. The total on-chip area is
estimated at 0.34 $mm^2$. 

In terms of utilization, the optimal configuration found by TEMPO enables some
networks to benefit substantially from HERO while others less so. Instances of
poor layer mapping to HERO include depthwise and group convolution layers that
were not considered when developing HERO as well as lowered layers that required more
compute resources than what was available in the configuration studied. 

To further the development of HERO explicit support of depthwise and grouped
convolution layers is necessary along with an exploration of alternative forms
of concurrency within HERO. Additionally, more convolution layer configurations
need to be supported directly in HERO, specifically convolution layers with a
stride size greater than 1. Along with increasing convolution support, support
for other layer types like Batch normalization layers and activation layers
needs to be included in HERO to minimize data movement between the CPU and HERO.
Similarly, lowering and lifting transformation required to extend support to
arbitrary convolution layers needs to be incorporated into HERO to minimize
off-chip data movement. Finally a larger scale exploration of different HERO
architectures using the developed simulation platform is required to validate
and refine TEMPO's analytical model.